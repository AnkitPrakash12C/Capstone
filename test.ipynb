{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T08:21:46.031768Z",
     "start_time": "2025-10-26T08:20:36.110858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import cv2  # OpenCV for preprocessing\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ],
   "id": "f114b28d706472ef",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T08:21:54.584329Z",
     "start_time": "2025-10-26T08:21:54.577765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATASET_PATH = \"D:/Sem7/Capstone 2/teaLeafBD/teaLeafBD\"\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "INITIAL_EPOCHS = 25\n",
    "FINE_TUNE_EPOCHS = 10"
   ],
   "id": "ecdbad35f485570e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T08:22:02.313126Z",
     "start_time": "2025-10-26T08:22:02.303499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_clahe(image):\n",
    "    \"\"\"\n",
    "    Applies CLAHE to the L channel of an image in LAB color space.\n",
    "    This enhances local contrast, which is great for highlighting disease spots.\n",
    "    \"\"\"\n",
    "    # The image is already rescaled to [0, 1] by the generator, so scale it back to [0, 255] for cv2\n",
    "    image_uint8 = (image * 255).astype(np.uint8)\n",
    "    # Convert image from RGB to LAB color space\n",
    "    lab_image = cv2.cvtColor(image_uint8, cv2.COLOR_RGB2LAB)\n",
    "    l_channel, a_channel, b_channel = cv2.split(lab_image)\n",
    "\n",
    "    # Apply CLAHE to the L-channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    cl_channel = clahe.apply(l_channel)\n",
    "\n",
    "    # Merge the CLAHE enhanced L-channel back with A and B channels\n",
    "    merged_channels = cv2.merge([cl_channel, a_channel, b_channel])\n",
    "\n",
    "    # Convert back to RGB color space and rescale to [0, 1]\n",
    "    final_image = cv2.cvtColor(merged_channels, cv2.COLOR_LAB2RGB)\n",
    "    return final_image / 255.0"
   ],
   "id": "bd5d049a256817d0",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T08:27:14.556826Z",
     "start_time": "2025-10-26T08:27:14.547225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    # NOTE: The preprocessing function is now handled differently in modern Keras.\n",
    "    # It's better to use tf.data.Dataset.map for this.\n",
    "    # However, for simplicity with ImageDataGenerator, we'll keep it but be mindful of data types.\n",
    "    # A safer approach is to apply rescaling first, then the function.\n",
    "    # Let's adjust the function to handle float inputs.\n",
    "    validation_split=0.2  # Use 20% of training data for validation\n",
    ")\n"
   ],
   "id": "554c0a1042c6f907",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T10:25:06.149236Z",
     "start_time": "2025-10-26T10:25:06.138925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_datagen.preprocessing_function = apply_clahe\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    preprocessing_function=apply_clahe # Apply CLAHE to test data as well\n",
    ")\n",
    "\n",
    "# Flow data from directories"
   ],
   "id": "e3bee5a6a5599db6",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T10:08:58.712107Z",
     "start_time": "2025-10-26T10:08:52.288308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make sure DATASET_PATH is set to your preprocessed directory\n",
    "# DATASET_PATH = \"D:/Sem7/Capstone 2/preprocessed_teaLeafBD\"\n",
    "\n",
    "# The ImageDataGenerator should have validation_split set\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,  # Example split, adjust as needed\n",
    "    preprocessing_function=apply_clahe\n",
    ")\n",
    "\n",
    "# Flow data directly from the root of the dataset directory\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    DATASET_PATH,  # Corrected: Point to the root directory\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Create the corresponding validation generator from the same directory\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    DATASET_PATH,  # Corrected: Point to the root directory\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# You would use your test_datagen on a separate, unseen test dataset folder\n",
    "# For example:\n",
    "# test_generator = test_datagen.flow_from_directory(\n",
    "#     'path/to/your/test_data',\n",
    "#     ...\n",
    "# )"
   ],
   "id": "2b740d28c1d90d39",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4223 images belonging to 7 classes.\n",
      "Found 1053 images belonging to 7 classes.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T10:50:08.800120Z",
     "start_time": "2025-10-26T10:50:08.561362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_model(num_classes):\n",
    "    \"\"\"\n",
    "    Builds a classification model using EfficientNetB0 for transfer learning.\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    inputs = Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "\n",
    "    # Load the base model\n",
    "    base_model = EfficientNetB0(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_tensor=inputs\n",
    "    )\n",
    "\n",
    "    # Freeze the layers of the base model\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Add custom classification head\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "\n",
    "    x = Dropout(0.5)(x) # Regularization\n",
    "    outputs = Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "    # Create the final model\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model(NUM_CLASSES)\n",
    "\n",
    "# Compile the model for initial training\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss=CategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ],
   "id": "aec29c50c4e94b8c",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NUM_CLASSES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 30\u001B[39m\n\u001B[32m     26\u001B[39m     model = Model(inputs, outputs)\n\u001B[32m     28\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n\u001B[32m---> \u001B[39m\u001B[32m30\u001B[39m model = build_model(\u001B[43mNUM_CLASSES\u001B[49m)\n\u001B[32m     32\u001B[39m \u001B[38;5;66;03m# Compile the model for initial training\u001B[39;00m\n\u001B[32m     33\u001B[39m model.compile(\n\u001B[32m     34\u001B[39m     optimizer=Adam(learning_rate=\u001B[32m1e-3\u001B[39m),\n\u001B[32m     35\u001B[39m     loss=CategoricalCrossentropy(),\n\u001B[32m     36\u001B[39m     metrics=[\u001B[33m\"\u001B[39m\u001B[33maccuracy\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m     37\u001B[39m )\n",
      "\u001B[31mNameError\u001B[39m: name 'NUM_CLASSES' is not defined"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T04:38:45.502549Z",
     "start_time": "2025-11-07T04:38:45.488981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import time\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 10\n",
    "PATIENCE = 15\n",
    "RF_FACTOR = 0.5\n",
    "NUM_CLASSES = 7"
   ],
   "id": "ba020a3815b7882a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T04:48:32.944550Z",
     "start_time": "2025-11-07T04:48:32.920593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATA_DIR = r\"D:/Sem7/Capstone 2/teaLeafBD/teaLeafBD\"\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "TEST_DIR = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "\n",
    "preprocess_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ],
   "id": "b0572e03edd04b41",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T04:51:29.313999Z",
     "start_time": "2025-11-07T04:51:23.155858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "import random\n",
    "\n",
    "\n",
    "DATA_DIR = r\"D:\\Sem7\\Capstone 2\\teaLeafBD\"\n",
    "\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    print(f\"ERROR: The path was not found at: {DATA_DIR}\")\n",
    "    print(\"Please make sure this path is correct.\")\n",
    "else:\n",
    "    print(f\"Loading data from: {DATA_DIR}\")\n",
    "\n",
    "\n",
    "train_augmentation_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=20),\n",
    "    transforms.RandomResizedCrop(256, scale=(0.8, 1.0)),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ColorJitter(brightness=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "preprocess_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "train_dataset_with_aug = datasets.ImageFolder(DATA_DIR, transform=train_augmentation_transform)\n",
    "dataset_no_aug = datasets.ImageFolder(DATA_DIR, transform=preprocess_transform)\n",
    "\n",
    "total_size = len(dataset_no_aug)\n",
    "\n",
    "test_size = int(total_size * 0.20)\n",
    "train_val_size = total_size - test_size\n",
    "\n",
    "\n",
    "indices = list(range(total_size))\n",
    "random.seed(42)\n",
    "random.shuffle(indices)\n",
    "\n",
    "train_val_indices = indices[:train_val_size]\n",
    "test_indices = indices[train_val_size:]\n",
    "\n",
    "val_size = int(train_val_size * 0.10)\n",
    "train_size = train_val_size - val_size\n",
    "\n",
    "train_indices = train_val_indices[:train_size]\n",
    "val_indices = train_val_indices[train_size:]\n",
    "\n",
    "\n",
    "train_subset = Subset(train_dataset_with_aug, train_indices)\n",
    "val_subset = Subset(dataset_no_aug, val_indices)\n",
    "test_subset = Subset(dataset_no_aug, test_indices)\n",
    "\n",
    "print(f\"Total images: {total_size}\")\n",
    "print(f\"Training images: {len(train_subset)}\")\n",
    "print(f\"Validation images: {len(val_subset)}\")\n",
    "print(f\"Testing images: {len(test_subset)}\")\n",
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "print(\"\\nDataLoaders created successfully.\")"
   ],
   "id": "36a3f3745cc9accf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: D:\\Sem7\\Capstone 2\\teaLeafBD\n",
      "Total images: 5276\n",
      "Training images: 3799\n",
      "Validation images: 422\n",
      "Testing images: 1055\n",
      "\n",
      "DataLoaders created successfully.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T04:58:57.374763Z",
     "start_time": "2025-11-07T04:58:56.336196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Building model for device: {DEVICE}\")\n",
    "\n",
    "class ECA(nn.Module):\n",
    "\n",
    "    def __init__(self, channels, kernel_size=3):\n",
    "        super(ECA, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.conv = nn.Conv1d(1, 1, kernel_size=kernel_size, padding=padding, bias=False)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        y = self.avg_pool(x)\n",
    "\n",
    "        y = y.squeeze(-1).squeeze(-1).unsqueeze(1)\n",
    "\n",
    "        y = self.conv(y)\n",
    "\n",
    "        y = y.squeeze(1).unsqueeze(-1).unsqueeze(-1)\n",
    "        y = self.sigmoid(y)\n",
    "\n",
    "        return x * y\n",
    "\n",
    "def create_m_efficientnet_b0_eca(num_classes=7):\n",
    "\n",
    "    model = models.efficientnet_b0(weights=None)\n",
    "\n",
    "    def replace_se_with_eca(module):\n",
    "        for name, child in module.named_children():\n",
    "            if isinstance(child, models.efficientnet.SqueezeExcitation):\n",
    "                channels = child.fc1.in_channels\n",
    "                setattr(module, name, ECA(channels=channels))\n",
    "            else:\n",
    "                replace_se_with_eca(child)\n",
    "\n",
    "    replace_se_with_eca(model.features)\n",
    "\n",
    "    model.features[6] = model.features[6][0]\n",
    "    model.features[7] = nn.Identity()\n",
    "\n",
    "\n",
    "    orig_stage9 = model.features[8]\n",
    "    out_channels = orig_stage9[0].out_channels\n",
    "    norm_layer = type(orig_stage9[1])\n",
    "    activation_layer = type(orig_stage9[2])\n",
    "\n",
    "    new_in_channels = 192\n",
    "\n",
    "    model.features[8] = models.efficientnet.Conv2dNormActivation(\n",
    "        new_in_channels,\n",
    "        out_channels,\n",
    "        kernel_size=1,\n",
    "        stride=1,\n",
    "        norm_layer=norm_layer,\n",
    "        activation_layer=activation_layer,\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    NUM_CLASSES = 7\n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Linear(in_features, NUM_CLASSES)\n",
    "\n",
    "    print(\"Model m-EfficientNetB0+ECA created successfully.\")\n",
    "    return model\n",
    "\n",
    "model = create_m_efficientnet_b0_eca().to(DEVICE)"
   ],
   "id": "e0027fcda89df22e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model for device: cpu\n",
      "Replacing SE modules with ECA...\n",
      "Replacement complete.\n",
      "Modifying Stage 7...\n",
      "Modifying Stage 8...\n",
      "Fixing Stage 9 (Conv1x1) input channels...\n",
      "Model m-EfficientNetB0+ECA created successfully.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-07T04:58:58.228075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 100\n",
    "PATIENCE = 15\n",
    "RF_FACTOR = 0.5\n",
    "NUM_CLASSES = 7\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=RF_FACTOR,\n",
    "    patience=PATIENCE\n",
    ")\n",
    "\n",
    "print(\"Optimizer, Loss, and Scheduler are set up.\")\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    epoch_loss = running_loss / len(all_labels)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average='macro', zero_division=0\n",
    "    )\n",
    "\n",
    "    return epoch_loss, acc * 100, precision * 100, recall * 100, f1 * 100\n",
    "\n",
    "print(\"Starting training...\")\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc, val_prec, val_recall, val_f1 = validate_epoch(model, val_loader, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | \"\n",
    "          f\"Time: {(end_time - start_time):.2f}s\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f}, Val Acc:   {val_acc:.2f}% | \"\n",
    "          f\"Val F1: {val_f1:.2f}%\")\n",
    "\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"m_efficientnet_b0_eca_best.pth\")\n",
    "        print(f\"  -> New best model saved with val_loss: {val_loss:.4f}\")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "print(\"\\nLoading best model for final testing...\")\n",
    "model.load_state_dict(torch.load(\"m_efficientnet_b0_eca_best.pth\"))\n",
    "\n",
    "test_loss, test_acc, test_prec, test_recall, test_f1 = validate_epoch(\n",
    "    model, test_loader, criterion\n",
    ")\n",
    "\n",
    "print(f\"--- FINAL TEST RESULTS ---\")\n",
    "print(f\"  Test Loss:     {test_loss:.4f}\")\n",
    "print(f\"  Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"  Test Precision (Macro): {test_prec:.2f}%\")\n",
    "print(f\"  Test Recall (Macro):    {test_recall:.2f}%\")\n",
    "print(f\"  Test F1-Score (Macro):  {test_f1:.2f}%\")"
   ],
   "id": "77b673fdb1c5093e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer, Loss, and Scheduler are set up.\n",
      "Starting training...\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T07:57:08.931725Z",
     "start_time": "2025-11-13T07:57:08.850628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ],
   "id": "6c30b68958a5511",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T07:57:09.795956Z",
     "start_time": "2025-11-13T07:57:09.665693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ],
   "id": "1a7ae12aada31043",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T07:57:10.323528Z",
     "start_time": "2025-11-13T07:57:10.281478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# PART 2: ECA MODULE & M-EFFICIENTNETB0 MODEL\n",
    "# =============================================================================\n",
    "\n",
    "# [cite_start]Define the ECA Module (as per paper description [cite: 293-308] and Figure 8)\n",
    "class ECA(nn.Module):\n",
    "    \"\"\"Efficient Channel Attention module\"\"\"\n",
    "    def __init__(self, in_channels, kernel_size=3):\n",
    "        super(ECA, self).__init__()\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        # 1D convolution for local cross-channel interaction\n",
    "        self.conv = nn.Conv1d(1, 1, kernel_size=kernel_size, padding=(kernel_size - 1) // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Global Average Pooling\n",
    "        y = self.gap(x)\n",
    "\n",
    "        # Squeeze, Conv1D, Sigmoid\n",
    "        # B, C, 1, 1 -> B, C, 1 -> B, 1, C\n",
    "        y = y.squeeze(-1).permute(0, 2, 1)\n",
    "        # B, 1, C -> B, 1, C\n",
    "        y = self.conv(y)\n",
    "        # B, 1, C -> B, C, 1\n",
    "        y = y.permute(0, 2, 1)\n",
    "\n",
    "        # Apply sigmoid activation\n",
    "        y = self.sigmoid(y)\n",
    "\n",
    "        # B, C, 1 -> B, C, 1, 1\n",
    "        y = y.unsqueeze(-1)\n",
    "\n",
    "        # Element-wise multiplication\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "# Helper function to replace SE modules with ECA modules\n",
    "def replace_se_with_eca(module):\n",
    "    \"\"\"\n",
    "    Recursively iterates through all modules and replaces SqueezeExcitation\n",
    "    with our ECA module.\n",
    "    \"\"\"\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, models.efficientnet.SqueezeExcitation):\n",
    "            # The SqueezeExcitation module stores the input channels in its\n",
    "            # first convolutional layer (fc1).\n",
    "            in_channels = child.fc1.in_channels\n",
    "\n",
    "            # Replace it with our ECA block\n",
    "            setattr(module, name, ECA(in_channels=in_channels))\n",
    "        elif len(list(child.children())) > 0:\n",
    "            # Recurse\n",
    "            replace_se_with_eca(child)\n",
    "\n",
    "def create_model(num_classes=7):\n",
    "    \"\"\"\n",
    "    Creates the modified EfficientNetB0 (m-EfficientNetB0) with ECA.\n",
    "    \"\"\"\n",
    "    # 1. Load pre-trained EfficientNetB0\n",
    "    model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "\n",
    "    # 2. Replace all SE modules with ECA modules\n",
    "    replace_se_with_eca(model)\n",
    "\n",
    "    # 3. Apply architectural modifications for m-EfficientNetB0\n",
    "\n",
    "    # --- THIS IS THE FINAL FIX ---\n",
    "\n",
    "    # Reduce Stage 7 (features[6]) to one block\n",
    "    # We MUST keep the first block [0] because it's the only one\n",
    "    # that handles the channel transition from 112 (from Stage 5) to 192.\n",
    "    model.features[6] = model.features[6][0]\n",
    "\n",
    "    # Remove Stage 8 (features[7]) entirely\n",
    "    model.features[7] = nn.Identity()\n",
    "\n",
    "    # CRITICAL FIX: Adjust Stage 9 (features[8])\n",
    "    # The original Stage 9 (features[8][0]) expects 320 channels from Stage 8.\n",
    "    # Our new flow is: Stage 7 (out 192) -> Stage 8 (removed) -> Stage 9.\n",
    "    # Therefore, Stage 9 will receive 192 channels, not 320.\n",
    "    # We must rebuild the first Conv2d layer of Stage 9 to accept 192 channels.\n",
    "\n",
    "    # Get the original weights and parameters from the old layer\n",
    "    old_conv = model.features[8][0]\n",
    "    out_channels = old_conv.out_channels\n",
    "    kernel_size = old_conv.kernel_size\n",
    "    stride = old_conv.stride\n",
    "    padding = old_conv.padding\n",
    "    bias = (old_conv.bias is not None)\n",
    "\n",
    "    # Create the new layer with corrected in_channels\n",
    "    new_conv = nn.Conv2d(in_channels=192,\n",
    "                         out_channels=out_channels,\n",
    "                         kernel_size=kernel_size,\n",
    "                         stride=stride,\n",
    "                         padding=padding,\n",
    "                         bias=bias)\n",
    "\n",
    "    # Replace the old layer with the new one\n",
    "    model.features[8][0] = new_conv\n",
    "\n",
    "    # ---------------------------------\n",
    "\n",
    "    # 4. Replace the final classifier head\n",
    "    # This remains correct. The input to the classifier is 1280 channels.\n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.2, inplace=True), # Default dropout in EfficientNet\n",
    "        nn.Linear(in_features, num_classes)\n",
    "    )\n",
    "\n",
    "    return model.to(device)"
   ],
   "id": "727ac5f763ec8de5",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T07:57:12.704646Z",
     "start_time": "2025-11-13T07:57:11.142936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATA_DIR = \"D:/Sem7/Capstone 2/teaLeafBD/teaLeafBD\" # <<< CHANGE THIS\n",
    "BATCH_SIZE = 16 #\n",
    "NUM_CLASSES = 7 # 6 diseases + 1 healthy [cite: 101, 352]\n",
    "IMG_SIZE = 256 # Standardized size [cite: 345]\n",
    "\n",
    "# --- Data Augmentation (as per Table 3 ) ---\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)), # Random crop 80-100%\n",
    "    transforms.RandomVerticalFlip(p=0.5), # Vertical flip 50%\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # Horizontal flip 50%\n",
    "    transforms.RandomRotation(20), # +/- 20 degrees\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)), # 0-10% translation\n",
    "    transforms.ColorJitter(brightness=0.2), # +/- 20% brightness\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # Standard normalization\n",
    "])\n",
    "\n",
    "# For validation and testing, just resize and normalize\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# --- Load and Split Dataset ---\n",
    "# Assuming DATA_DIR has subfolders for each of the 7 classes\n",
    "try:\n",
    "    full_dataset = datasets.ImageFolder(DATA_DIR)\n",
    "    print(f\"Found {len(full_dataset)} images in {len(full_dataset.classes)} classes.\")\n",
    "    print(\"Classes:\", full_dataset.classes)\n",
    "\n",
    "    # Verify class count\n",
    "    if len(full_dataset.classes) != NUM_CLASSES:\n",
    "        print(f\"Warning: Expected {NUM_CLASSES} classes, but found {len(full_dataset.classes)}.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Data directory not found at {DATA_DIR}\")\n",
    "    print(\"Please download the teaLeafBD dataset and set the DATA_DIR variable.\")\n",
    "    # Stop execution if data isn't found\n",
    "    raise\n",
    "\n",
    "# Splitting data 80% train_phase, 20% test_phase\n",
    "total_count = len(full_dataset)\n",
    "test_count = int(0.2 * total_count)\n",
    "train_val_count = total_count - test_count\n",
    "\n",
    "train_val_dataset, test_dataset = random_split(full_dataset, [train_val_count, test_count],\n",
    "                                         generator=torch.Generator().manual_seed(42))\n"
   ],
   "id": "78f2ae1cb5804a18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5276 images in 7 classes.\n",
      "Classes: ['1. Tea algal leaf spot', '2. Brown Blight', '3. Gray Blight', '4. Helopeltis', '5. Red spider', '6. Green mirid bug', '7. Healthy leaf']\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T07:57:13.518232Z",
     "start_time": "2025-11-13T07:57:13.390810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_count = int(0.9 * train_val_count)\n",
    "val_count = train_val_count - train_count\n",
    "\n",
    "train_dataset, val_dataset = random_split(train_val_dataset, [train_count, val_count],\n",
    "                                          generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Apply the correct transforms to each split\n",
    "train_dataset.dataset.transform = train_transform\n",
    "val_dataset.dataset.transform = val_test_transform\n",
    "test_dataset.dataset.transform = val_test_transform\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Training images: {len(train_dataset)}\")\n",
    "print(f\"Validation images: {len(val_dataset)}\")\n",
    "print(f\"Testing images: {len(test_dataset)}\")\n"
   ],
   "id": "78a149a054560d20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 3798\n",
      "Validation images: 423\n",
      "Testing images: 1055\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T07:57:15.284482Z",
     "start_time": "2025-11-13T07:57:14.150952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# PART 4: TRAINING SETUP\n",
    "# =============================================================================\n",
    "\n",
    "model = create_model(num_classes=NUM_CLASSES)\n",
    "\n",
    "# --- Hyperparameters from Table 1 ---\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 100\n",
    "PATIENCE = 15\n",
    "REDUCTION_FACTOR = 0.5\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# --- THIS IS THE FIX ---\n",
    "# The 'verbose' argument is deprecated/removed in newer PyTorch versions.\n",
    "# The scheduler will still print updates by default when the LR changes.\n",
    "scheduler = ReduceLROnPlateau(optimizer,\n",
    "                              mode='min',\n",
    "                              factor=REDUCTION_FACTOR,\n",
    "                              patience=PATIENCE)\n",
    "# ---------------------"
   ],
   "id": "104f01a74cc3a789",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T08:53:32.259361Z",
     "start_time": "2025-11-13T07:57:15.776567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # --- Training Phase ---\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    # --- Epoch Statistics ---\n",
    "    epoch_train_loss = train_loss / len(train_dataset)\n",
    "    epoch_val_loss = val_loss / len(val_dataset)\n",
    "    epoch_val_acc = val_corrects.double() / len(val_dataset)\n",
    "\n",
    "    # Adjust learning rate based on validation loss [cite: 318]\n",
    "    scheduler.step(epoch_val_loss)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | \"\n",
    "          f\"Time: {end_time - start_time:.0f}s | \"\n",
    "          f\"Train Loss: {epoch_train_loss:.4f} | \"\n",
    "          f\"Val Loss: {epoch_val_loss:.4f} | \"\n",
    "          f\"Val Acc: {epoch_val_acc:.4f}\")\n",
    "\n",
    "    # Save the best model\n",
    "    if epoch_val_acc > best_acc:\n",
    "        best_acc = epoch_val_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_wts, 'm-EfficientNetB0-ECA_best.pth')\n",
    "\n",
    "print(f\"Training complete. Best Val Acc: {best_acc:.4f}\")\n"
   ],
   "id": "2530f9262d2ae82b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Time: 1353s | Train Loss: 0.9070 | Val Loss: 0.6469 | Val Acc: 0.7896\n",
      "Epoch 2/100 | Time: 1159s | Train Loss: 0.4964 | Val Loss: 0.5237 | Val Acc: 0.8392\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[29]\u001B[39m\u001B[32m, line 18\u001B[39m\n\u001B[32m     15\u001B[39m outputs = model(inputs)\n\u001B[32m     16\u001B[39m loss = criterion(outputs, labels)\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     19\u001B[39m optimizer.step()\n\u001B[32m     21\u001B[39m train_loss += loss.item() * inputs.size(\u001B[32m0\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Sem6\\Capstone 2\\Lib\\site-packages\\torch\\_tensor.py:625\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    615\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    616\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    617\u001B[39m         Tensor.backward,\n\u001B[32m    618\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    623\u001B[39m         inputs=inputs,\n\u001B[32m    624\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m625\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    626\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    627\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Sem6\\Capstone 2\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    349\u001B[39m     retain_graph = create_graph\n\u001B[32m    351\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    353\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m354\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs_tuple\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    362\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Sem6\\Capstone 2\\Lib\\site-packages\\torch\\autograd\\graph.py:841\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    839\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    840\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m841\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    842\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    843\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    844\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    845\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "28d23b2b0b8b2e81"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
